{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "lab_assignment_4.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "img_dir = \"https://vizwiz.cs.colorado.edu//VizWiz_visualization_img/\""
      ],
      "metadata": {
        "id": "pBDGhKZDX2qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the file to extract each dataset example with label\n",
        "import requests\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from keras.layers import TextVectorization\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from collections import Counter\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "splits = ['train', 'val', 'test']\n",
        "data_splits = []\n",
        "embed_dim = 100\n",
        "vectorizer = TextVectorization(max_tokens=20600, output_sequence_length=embed_dim)\n",
        "\n",
        "# Splitting the data into different sets eg. (train, validation, test)\n",
        "for split in splits:\n",
        "    annotation_file = \"https://ivc.ischool.utexas.edu/VizWiz_final/vqa_data/Annotations/%s.json\" %split\n",
        "    split_data = requests.get(annotation_file, allow_redirects=True)\n",
        "    data_splits.append(split_data.json())\n",
        "\n",
        "# Extract Vocab from validation and training splits\n",
        "train_questions = [s['question'] for s in data_splits[0]]\n",
        "question_pool = train_questions\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(question_pool).batch(128) ## Read batches of 128 samples\n",
        "vectorizer.adapt(text_ds)\n",
        "vocab = vectorizer.get_vocabulary()\n",
        "\n",
        "train_samps = 2000\n",
        "val_samps = 500\n",
        "test_samps = 1000\n",
        "num_classes = 1000\n",
        "\n",
        "y_train_ques = []\n",
        "y_val_ques = []\n",
        "y_test_ques = []\n",
        "y_train_ques_samp = []\n",
        "y_val_ques_samp = []\n",
        "y_test_ques_samp = []\n",
        "\n",
        "# Create embedding matrix for train data\n",
        "X_train_ques = vectorizer(np.array([[s['question']] for s in data_splits[0][:train_samps]]))\n",
        "\n",
        "for samp in data_splits[0][:train_samps]:\n",
        "  # retrieve the first answer from each question image pair for truth labels\n",
        "  y_train_ques.append(samp['answers'][0]['answer'])\n",
        "\n",
        "  # Build the list of all possible answers from the train set to create the most frequent answers\n",
        "  for ans_list in samp['answers']:\n",
        "    y_train_ques_samp.append(ans_list['answer'].lower())\n",
        "\n",
        "for samp in data_splits[1][:val_samps]:\n",
        "   # retrieve the first answer from each question image pair for truth labels\n",
        "  y_val_ques.append(samp['answers'][0]['answer'])\n",
        "  \n",
        "  # Build the list of all possible answers from the validation set to create the most frequent answers\n",
        "  for ans_list in samp['answers']:\n",
        "    y_val_ques_samp.append(ans_list['answer'].lower())\n",
        "\n",
        "# Find the 1000 most frequent answers\n",
        "ans_counter = Counter(y_val_ques + y_train_ques_samp)\n",
        "most_freq = ans_counter.most_common(num_classes)\n",
        "y_ques = np.array([ans[0] for ans in most_freq])\n",
        "y_ques_enc = to_categorical(np.arange(num_classes))\n",
        "ind_default = np.nonzero(y_ques == 'unanswerable')[0]\n",
        "if (ind_default.shape[0] < 1):\n",
        "  ind_default = num_classes-1\n",
        "  y_ques[ind_default] = 'unanswerable'\n",
        "else:\n",
        "  ind_default = ind_default[0]\n",
        "\n",
        "y_train_ind = []\n",
        "\n",
        "# Use the most frequent answers to assign labels to each answer in the training set\n",
        "for ans in y_train_ques:\n",
        "  match = False\n",
        "\n",
        "  for ind, freq_ans in enumerate(y_ques):\n",
        "    if (freq_ans == ans):\n",
        "      match = True\n",
        "      y_train_ind.append(ind)\n",
        "      break\n",
        "  # If the training example is not found, assign it the 'unnasigned' label at index 0\n",
        "  if (not match):\n",
        "    y_train_ind.append(ind_default)\n",
        "\n",
        "y_val_ind = []\n",
        "# Use the most frequent answers to assign labels to each answer in the training set\n",
        "for ans in y_val_ques:\n",
        "  match = False\n",
        "\n",
        "  for ind, freq_ans in enumerate(y_ques):\n",
        "    if (freq_ans == ans):\n",
        "      match = True\n",
        "      y_val_ind.append(ind)\n",
        "      break\n",
        "\n",
        "  # If the training example is not found, assign it the 'unnasigned' label at index 0\n",
        "  if (not match):\n",
        "    y_val_ind.append(ind_default)\n",
        "\n",
        "y_train_ind_enc = np.zeros((train_samps, num_classes))\n",
        "y_train_ind_enc[np.arange(len(y_train_ind)),y_train_ind] = 1\n",
        "y_train_ind_enc.astype(np.int64)\n",
        "\n",
        "y_val_ind_enc = np.zeros((val_samps, num_classes))\n",
        "y_val_ind_enc[np.arange(len(y_val_ind)),y_val_ind] = 1\n",
        "y_val_ind_enc.astype(np.int64)\n",
        "\n",
        "X_val_ques = vectorizer(np.array([[s['question']] for s in data_splits[1][:val_samps]]))\n",
        "X_test_ques = vectorizer(np.array([[s['question']] for s in data_splits[2][:test_samps]]))\n",
        "X_train_img = np.array([cv2.resize(io.imread(img_dir + s['image']), (360, 480)) for s in data_splits[0][:train_samps]])\n",
        "X_val_img = np.array([cv2.resize(io.imread(img_dir + s['image']), (360, 480)) for s in data_splits[1][:val_samps]])\n",
        "X_test_img = np.array([cv2.resize(io.imread(img_dir + s['image']), (360, 480)) for s in data_splits[2][:test_samps]])"
      ],
      "metadata": {
        "id": "xdQiNRN0X_Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import LSTM, Conv2D, MaxPooling2D, Dense, Input, Flatten, Concatenate, Embedding, Dropout\n",
        "\n",
        "def vqa_mod1(): # Higher LSTM and convolutional emphasis\n",
        "  inputs_cnn = Input(shape=(480, 360, 3))\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs_cnn)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Flatten()(inputs)\n",
        "\n",
        "  question_input = Input(shape=(None,), dtype=\"int64\")\n",
        "  embedded_sequences = Embedding(20000, 100, trainable=True)(question_input)\n",
        "  lstm_mod = LSTM(256, return_sequences=True)(embedded_sequences)\n",
        "  lstm_mod = LSTM(256)(lstm_mod) # Recently added\n",
        "\n",
        "  merged = Concatenate()([inputs, lstm_mod])\n",
        "  output = Dense(100, activation='softmax')(merged)\n",
        "  mymod = Model([inputs_cnn, question_input], output)\n",
        "\n",
        "  mymod.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
        "  mymod.summary()\n",
        "\n",
        "  #mymod.fit([X_train_img, X_train_ques], y_train_ind_enc, batch_size=100, epochs=15, verbose=0, shuffle=True)\n",
        "\n",
        "  #return mymod\n",
        "\n",
        "def vqa_mod2(): # Higher LSTM and convolutional emphasis\n",
        "  inputs_cnn = Input(shape=(480, 360, 3))\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs_cnn)\n",
        "  inputs = MaxPooling2D((7, 7))(inputs)\n",
        "  inputs = Flatten()(inputs)\n",
        "\n",
        "  question_input = Input(shape=(None,), dtype=\"int64\")\n",
        "  embedded_sequences = Embedding(len(vocab), embed_dim, trainable=True)(question_input)\n",
        "  lstm_mod = LSTM(256, return_sequences=True)(embedded_sequences)\n",
        "  lstm_mod = LSTM(256)(lstm_mod) # Recently added\n",
        "\n",
        "  merged = Concatenate()([inputs, lstm_mod])\n",
        "  output = Dense(num_classes, activation='softmax')(merged)\n",
        "  mymod = Model([inputs_cnn, question_input], output)\n",
        "\n",
        "  mymod.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
        "  mymod.summary()\n",
        "\n",
        "  #mymod.fit([X_train_img, X_train_ques], y_train_ind_enc, batch_size=100, epochs=15, verbose=0, shuffle=True)\n",
        "\n",
        "  #return mymod\n",
        "\n",
        "def vqa_mod3(): # Higher LSTM and convolutional emphasis\n",
        "  inputs_cnn = Input(shape=(480, 360, 3))\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs_cnn)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Flatten()(inputs)\n",
        "\n",
        "  question_input = Input(shape=(None,), dtype=\"int64\")\n",
        "  embedded_sequences = Embedding(len(vocab), embed_dim, trainable=True)(question_input)\n",
        "  lstm_mod = LSTM(256)(embedded_sequences) # Recently addedb\n",
        "\n",
        "  merged = Concatenate()([inputs, lstm_mod])\n",
        "  output = Dense(num_classes, activation='softmax')(merged)\n",
        "  mymod = Model([inputs_cnn, question_input], output)\n",
        "\n",
        "  mymod.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
        "  mymod.summary()\n",
        "\n",
        "  #mymod.fit([X_train_img, X_train_ques], y_train_ind_enc, batch_size=100, epochs=15, verbose=0, shuffle=True)\n",
        "\n",
        "  #return mymod"
      ],
      "metadata": {
        "id": "Og4temz8oNic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vqa_mod1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86vT5BtArg4U",
        "outputId": "b7388169-7eeb-457a-f86a-4cdff58df598"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)           [(None, 480, 360, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 480, 360, 15  420         ['input_5[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 240, 180, 15  0          ['conv2d_6[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 240, 180, 15  2040        ['max_pooling2d_6[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_7 (MaxPooling2D)  (None, 120, 90, 15)  0          ['conv2d_7[0][0]']               \n",
            "                                                                                                  \n",
            " input_6 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 120, 90, 15)  2040        ['max_pooling2d_7[0][0]']        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 100)    2000000     ['input_6[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d_8 (MaxPooling2D)  (None, 60, 45, 15)  0           ['conv2d_8[0][0]']               \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  (None, None, 256)    365568      ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 40500)        0           ['max_pooling2d_8[0][0]']        \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 256)          525312      ['lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 40756)        0           ['flatten_2[0][0]',              \n",
            "                                                                  'lstm_3[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 100)          4075700     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,971,080\n",
            "Trainable params: 6,971,080\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use np.argmax of the ground-truth labels to see if there are any matches\n",
        "def comp_acc(mypreds, cdataset):\n",
        "  acc = []\n",
        "  for pred_ind, pred in enumerate(mypreds):\n",
        "    pred_labels = []\n",
        "    word_pred = y_ques[pred]\n",
        "    for samp in data_splits[cdataset][pred_ind]['answers']:\n",
        "    # retrieve the first answer from each question image pair for truth labels\n",
        "      #print(data_splits[1][pred_ind])\n",
        "      pred_labels.append(samp['answer'])\n",
        "    num_match = np.nonzero(word_pred == np.array(pred_labels))[0].shape[0] # Find matching labels to compute the accuracy\n",
        "    acc.append(min((num_match / 3), 1))\n",
        "    # Calculate the number of matches and from there calculate the 'special' accuracy metric\n",
        "  return acc"
      ],
      "metadata": {
        "id": "G3c7ohCpDps3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "mymod1 = vqa_mod1()\n",
        "mypreds1 = mymod1.predict([X_val_img, X_val_ques])\n",
        "myacc1 = comp_acc(np.argmax(mypreds1, axis=1), 1)\n",
        "del mymod1\n",
        "del mypreds1\n",
        "gc.collect()\n",
        "\n",
        "mymod2 = vqa_mod2()\n",
        "mypreds2 = mymod2.predict([X_val_img, X_val_ques])\n",
        "myacc2 = comp_acc(np.argmax(mypreds2, axis=1), 1)\n",
        "del mymod2\n",
        "del mypreds2\n",
        "gc.collect()\n",
        "\n",
        "mymod3 = vqa_mod3()\n",
        "mypreds3 = mymod3.predict([X_val_img, X_val_ques])\n",
        "myacc3 = comp_acc(np.argmax(mypreds3, axis=1), 1)"
      ],
      "metadata": {
        "id": "c4z2df4DVSrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Mean Accuracy on model 1 = {round(np.mean(myacc1),2)}')\n",
        "print(f'Mean Accuracy on model 1 = {round(np.mean(myacc2),2)}')\n",
        "print(f'Mean Accuracy on model 1 = {round(np.mean(myacc3),2)}')"
      ],
      "metadata": {
        "id": "ftjDlNjVHCIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "mypreds4 = mymod3.predict([X_test_img, X_test_ques])\n",
        "mypreds4 = y_ques[np.argmax(mypreds4, axis=1)]\n",
        "df = pd.DataFrame(mypreds4)\n",
        "df.to_csv(\"results.csv\", header = None, index = None)\n",
        "del mymod3\n",
        "del mypreds3\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "hpYkjkxEkOkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vqa_mod4(myepochs): # Higher LSTM and convolutional emphasis\n",
        "  inputs_cnn = Input(shape=(480, 360, 3))\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs_cnn)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Conv2D(15, (3, 3), activation='relu', padding='same', input_shape=(480, 360, 3))(inputs)\n",
        "  inputs = MaxPooling2D((2, 2))(inputs)\n",
        "  inputs = Flatten()(inputs)\n",
        "\n",
        "  question_input = Input(shape=(None,), dtype=\"int64\")\n",
        "  embedded_sequences = Embedding(len(vocab), embed_dim, trainable=True)(question_input)\n",
        "  lstm_mod = LSTM(256)(embedded_sequences) # Recently addedb\n",
        "\n",
        "  merged = Concatenate()([inputs, lstm_mod])\n",
        "  output = Dense(num_classes, activation='softmax')(merged)\n",
        "  mymod = Model([inputs_cnn, question_input], output)\n",
        "\n",
        "  mymod.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
        "  #mymod.summary()\n",
        "\n",
        "  mymod.fit([X_train_img, X_train_ques], y_train_ind_enc, batch_size=100, epochs=myepochs, verbose=0, shuffle=True)\n",
        "\n",
        "  return mymod\n",
        "\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "i = 0\n",
        "for epoch in range(1,16):\n",
        "  i += 1\n",
        "  print(epoch)\n",
        "  mymod1 = vqa_mod4(epoch)\n",
        "  mypreds1 = mymod1.predict([X_train_img, X_train_ques])\n",
        "  train_acc.append(round(np.mean(comp_acc(np.argmax(mypreds1, axis=1), 0)),2))\n",
        "  mypreds2 = mymod1.predict([X_val_img, X_val_ques])\n",
        "  val_acc.append(round(np.mean(comp_acc(np.argmax(mypreds2, axis=1), 1)),2))\n",
        "  del mymod1\n",
        "  del mypreds1\n",
        "  del mypreds2\n",
        "  gc.collect()"
      ],
      "metadata": {
        "id": "iYSGJfUSlB8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "epochs = np.arange(1,16)\n",
        "plt.plot(epochs, train_acc, color = 'green', label = 'Training')\n",
        "plt.plot(epochs, val_acc, color = 'orange', label = 'Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('VQA Model Performance')\n",
        "plt.legend()\n",
        "plt.savefig('vqa_model.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JAKZWQD2me-8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}